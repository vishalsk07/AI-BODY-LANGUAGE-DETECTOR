VISHAL SHIVKKUMAR
PES UNIVERSITY


Developed an AI Body Language Decoder using Mediapipe, OpenCV, and Python, aimed at analyzing human body language in real-time.
Set up and configured MediaPipe for Python to estimate face and body poses, utilizing the webcam for live video feed capture.
Integrated OpenCV to manage video stream processing, enabling real-time pose estimation and visualization.
Implemented algorithms to accurately detect key body landmarks and joints, focusing on capturing precise movement and posture data.
Collected joint coordinate data from the pose estimation output, and processed this data using Pandas for further analysis and model training.
Designed and trained a custom pose classification model using Scikit-Learn, tailored to identify specific body language patterns and gestures.
Utilized machine learning techniques to enhance the model's accuracy in decoding body language cues, considering various angles and poses.
Enabled real-time body language decoding, allowing the system to provide immediate feedback and analysis based on the detected poses.
Conducted extensive testing and validation of the model to ensure reliable performance across different individuals and environments.
Optimized the system for real-time performance, ensuring smooth operation and minimal latency during live body language analysis.









